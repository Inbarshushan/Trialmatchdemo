
import streamlit as st
from PyPDF2 import PdfReader
from openai import OpenAI

# Load API key securely
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# Page config and logo
st.set_page_config(page_title="TrialMatch Demo", page_icon="ğŸ”¬")
st.image("A_logo_for_a_company_named_TrialMatch_is_displayed.png", width=180)
st.title("TrialMatch â€“ ×”×ª×××ª ××˜×•×¤×œ×™× ×œ××—×§×¨×™× ×§×œ×™× ×™×™× ×‘×××¦×¢×•×ª ×‘×™× ×” ××œ××›×•×ª×™×ª")

# File upload section
protocol_file = st.file_uploader("ğŸ“„ ×”×¢×œ×” ××ª ×¤×¨×•×˜×•×§×•×œ ×”××—×§×¨ (PDF)", type="pdf")
medical_files = st.file_uploader("ğŸ“ ×”×¢×œ×” ×§×‘×¦×™ ××™×“×¢ ×¨×¤×•××™ ×©×œ ×”××˜×•×¤×œ (PDF)", type="pdf", accept_multiple_files=True)

if protocol_file and medical_files:
    with st.spinner("ğŸ” ××‘×¦×¢ × ×™×ª×•×— ×•×”×©×•×•××”..."):
        # Extract text from protocol
        protocol_reader = PdfReader(protocol_file)
        protocol_text = "\n".join([page.extract_text() for page in protocol_reader.pages])

        # Extract inclusion/exclusion criteria using GPT
        criteria_prompt = f'''
        ××ª×” ××§×‘×œ ×›×§×œ×˜ ×˜×§×¡×˜ ××ª×•×š ×¤×¨×•×˜×•×§×•×œ ×©×œ ××—×§×¨ ×§×œ×™× ×™.
        ×× × ××ª×¨ ×¨×§ ××ª ×¡×¢×™×¤×™ ×§×¨×™×˜×¨×™×•× ×™ ×”×”×›×œ×œ×” ×•××™-×”×›×œ×œ×”.
        ×”×—×–×¨ ×¨×§ ××ª ×”×˜×§×¡×˜ ×©×œ ×”×§×¨×™×˜×¨×™×•× ×™× ×‘×¦×•×¨×” ×‘×¨×•×¨×”, ×›×š:

        ×§×¨×™×˜×¨×™×•× ×™ ×”×›×œ×œ×”:
        - ...
        - ...

        ×§×¨×™×˜×¨×™×•× ×™ ××™-×”×›×œ×œ×”:
        - ...
        - ...

        ×˜×§×¡×˜ ×”×¤×¨×•×˜×•×§×•×œ:
        {protocol_text[:6000]}
        '''

        extracted_criteria = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": criteria_prompt}]
        ).choices[0].message.content

        # Combine all medical files
        all_medical_text = ""
        for file in medical_files:
            reader = PdfReader(file)
            all_medical_text += "\n".join([page.extract_text() for page in reader.pages])

        # Matching logic
        matching_prompt = f'''
        ×™×© ×‘×™×“×š ××ª ×§×¨×™×˜×¨×™×•× ×™ ×”×”×›×œ×œ×” ×•×”××™-×”×›×œ×œ×” ×œ××—×§×¨ ×§×œ×™× ×™, ×•×›×Ÿ ××™×“×¢ ×¨×¤×•××™ ×©×œ ××˜×•×¤×œ×ª.

        ×¢×œ×™×š ×œ×”×©×•×•×ª ×‘×™×Ÿ ×©× ×™×”× ×•×œ×›×ª×•×‘ ×‘×¦×•×¨×” ×‘×¨×•×¨×”:

        - ×¢×‘×•×¨ ×›×œ ×§×¨×™×˜×¨×™×•×Ÿ ×¦×™×™×Ÿ ×× ××ª×§×™×™× ××• ×œ×, ×•×”×¡×‘×¨ ××“×•×¢.
        - ×× ×—×¡×¨ ××™×“×¢ â€“ ×¦×™×™×Ÿ ×–××ª ×‘××¤×•×¨×©.
        - ×‘×¡×™×•×, ×›×ª×•×‘ ×¤×¡×§×” ××¡×›××ª ×‘×¨×•×¨×”: ×”×× × ×¨××” ×©×”××˜×•×¤×œ×ª ××ª××™××” ×œ××—×§×¨? ×× ×œ× â€“ ××” ×—×¡×¨?

        ×§×¨×™×˜×¨×™×•× ×™ ××—×§×¨:
        {extracted_criteria}

        ××™×“×¢ ×¨×¤×•××™ ×©×œ ×”××˜×•×¤×œ×ª:
        {all_medical_text[:6000]}
        '''

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": matching_prompt}]
        ).choices[0].message.content

        st.subheader("ğŸ§  ×ª×•×¦××ª ×”×”×ª×××”:")
        st.markdown(response)

